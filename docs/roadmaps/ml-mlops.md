# ML / MLOps Roadmap

Part of the [project roadmap](../ROADMAP.md). Embedding pipeline, RAG, evaluation framework, and production ML practices.

## Phase 6a â€” Embeddings (~2 days)

- [ ] ChromaDB service in docker-compose, `core/db/chroma.py` client
- [ ] `core/db/embeddings.py` â€” all-MiniLM-L6-v2, composite text builder
- [ ] `scraper/src/embed_sync.py` â€” post-scrape embedding pipeline
- [ ] Embedding eval checkpoint â€” hit rate, MRR, bilingual overlap
  - Decision gate: bilingual overlap < 50% â†’ swap to multilingual-MiniLM

## Phase 6b â€” Claude Integration (~3 days)

- [ ] `backend/services/llm_service.py` â€” Claude Haiku wrapper with tool use
- [ ] `backend/services/rag_service.py` â€” 4-stage pipeline (parse â†’ retrieve â†’ recommend â†’ validate)
- [ ] `backend/services/rag_config.py` â€” versioned prompt/threshold config
- [ ] `backend/services/guardrails.py` â€” input validation, hallucination prevention

## Phase 6c â€” Bot Integration (~2 days)

- [ ] `/recommend` handler wired to RAG pipeline
- [ ] Conversation memory â€” `conversations` + `messages` tables, last 10 to Claude

## Phase 6d â€” MLOps Foundation (~3 days)

- [ ] LLM call logging â†’ PostgreSQL (function, model, tokens, cost, latency)
- [ ] Full RAG eval â€” automated checks + LLM-as-judge scoring
- [ ] User feedback loop â€” ðŸ‘ðŸ‘Ž buttons â†’ `recommendation_feedback` table
- [ ] Trace logging â€” full pipeline state per recommendation for reproducibility

## Phase 7 â€” ML Optimization (~4 days)

- [ ] HyDE for vague queries (hypothetical document embedding)
- [ ] Prompt caching for system prompts
- [ ] Semantic caching â€” second ChromaDB collection for query deduplication
- [ ] Eval in CI â€” quick (10 queries) on PR, full (50+) weekly

## Phase 8 â€” Advanced ML (~5 days, only if eval data justifies)

- [ ] Model comparison framework (`ml/compare_models.py`)
- [ ] Fine-tune embedding model with bilingual wine pairs
- [ ] Wine label scanner (Claude Vision)
- [ ] A/B testing prompts with tracked metrics
